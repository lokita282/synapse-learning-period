As we know loss functions measure how wrong the predictions are. To make an efficient model, we need to reduce the loss function to its minimum value. We basically use the hit and trial and tweak the model parameters so as to achieve the best output. If one was to go about this method manually, it would take an unrealistical amount of time because of the various permutation and combinations. Hence we use optimizers for this.  They tie together the loss function and model parameters by updating the model in response to the output of the loss function. In simpler terms, optimizers shape and mold your model into its most accurate possible form by futzing with the weights.